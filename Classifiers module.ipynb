{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from operator import itemgetter \n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X,Y =load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class compare_classifiers():\n",
    "    def __init__(self, \n",
    "                X: '(np ndarray) size of num_samplesxnum_features', \n",
    "                Y: '(np ndarray[int]) size of num_samples', \n",
    "                n_folds: '(int)',\n",
    "                random_state=456):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.n_folds = n_folds\n",
    "        self.kfold = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    def all_models(self):\n",
    "        param_grid = ParameterGrid({'C': [0.01, 0.1, 1, 10, 100], 'solver': ['lbfgs', 'liblinear']})\n",
    "        for param in param_grid:\n",
    "            model = LogisticRegression(class_weight='balanced', multi_class='ovr')\n",
    "            model.set_params(**param)\n",
    "            yield {'model':model, 'model_name':'Logistic', 'param': param}\n",
    "\n",
    "#         param_grid = ParameterGrid({'num_leaves': [4, 8, 32, 64], 'solver' = ['lbfgs', 'liblinear']})\n",
    "#         for param in param_grid:\n",
    "#             model = LGBMClassifier(class_weight='balanced', solver= , objective='multiclass')\n",
    "#             model.set_params(**param)\n",
    "#             yield (model, 'linear')\n",
    "        \n",
    "        param_grid = ParameterGrid({'C': [0.01, 0.1, 1, 10, 100]})\n",
    "        for param in param_grid:\n",
    "            model = SVC(class_weight='balanced',  kernel = 'linear')\n",
    "            model.set_params(**param)\n",
    "            yield {'model':model, 'model_name':'SVM_linear', 'param': param}\n",
    "        \n",
    "        param_grid = ParameterGrid({'C': [0.01, 0.1, 1, 10, 100]})\n",
    "        for param in param_grid:\n",
    "            model = SVC(class_weight='balanced',  kernel = 'rbf')\n",
    "            model.set_params(**param)\n",
    "            yield {'model':model, 'model_name':'SVM_rbf', 'param': param}\n",
    "        \n",
    "        param_grid = ParameterGrid({'criterion': [\"gini\", \"entropy\"], \n",
    "                                    'max_depth': [4, 12, 16, 24]})\n",
    "        for param in param_grid:\n",
    "            model = RandomForestClassifier(class_weight='balanced', max_features='log2', n_jobs=3)\n",
    "            model.set_params(**param)\n",
    "            yield {'model':model, 'model_name':'RandomForest', 'param': param}\n",
    "            \n",
    "        model = GaussianNB()\n",
    "        yield {'model':model, 'model_name':'GaussianNB', 'param': None}\n",
    "    def fit_models(self):\n",
    "        across_fold_UWf1s = []\n",
    "        across_fold_Wf1s = []\n",
    "        model_list = []\n",
    "        for ind, (train, test) in enumerate(self.kfold.split(self.x, self.y)):\n",
    "            print(f'fold: {ind}')\n",
    "            UWf1s = []\n",
    "            Wf1s = []\n",
    "            print(train)\n",
    "            print(test)\n",
    "            x_tr = self.x[train]\n",
    "            y_tr = self.y[train]\n",
    "            x_te = self.x[test]\n",
    "            y_te = self.y[test]\n",
    "            print('begin_training')\n",
    "            for model_dict in self.all_models():\n",
    "                print('fit model')\n",
    "                print(model_dict['model_name'])\n",
    "                print(model_dict['param'])\n",
    "                model_dict['model'].fit(x_tr, y_tr)\n",
    "                print('after fitting')\n",
    "                y_pred = model_dict['model'].predict(x_te)\n",
    "                print('after predicting')\n",
    "                UWf1s.append(f1_score(y_te, y_pred, average='macro'))\n",
    "                Wf1s.append(f1_score(y_te, y_pred, average='weighted'))\n",
    "                if ind == 0:\n",
    "                    model_list.append(model_dict['model_name'])\n",
    "            across_fold_UWf1s.append(UWf1s)\n",
    "            across_fold_Wf1s.append(Wf1s)\n",
    "            print(across_fold_UWf1s)\n",
    "            print(across_fold_Wf1s)\n",
    "        print('1')\n",
    "        across_fold_UWf1s = np.stack(across_fold_UWf1s)\n",
    "        across_fold_Wf1s = np.stack(across_fold_Wf1s)\n",
    "        across_fold_UWf1s = np.mean(across_fold_UWf1s,axis=0)\n",
    "        across_fold_Wf1s = np.mean(across_fold_Wf1s,axis=0)\n",
    "        f1s = (across_fold_UWf1s+across_fold_Wf1s)/2\n",
    "        best_dictionary = {}\n",
    "        print(len(model_list))\n",
    "        print(len(f1s))\n",
    "        for ind, (model_name, f1) in enumerate(zip(model_list, f1s)):\n",
    "            if model_name not in best_dictionary:\n",
    "                best_dictionary[model_name] = (ind, f1)\n",
    "            else:\n",
    "                if best_dictionary[model_name][1] < f1:\n",
    "                    best_dictionary[model_name] = (ind, f1)\n",
    "        for model_name in best_dictionary:\n",
    "            best_dictionary[model_name] = {'Unweighted_f1': across_fold_UWf1s[best_dictionary[model_name][0]],\n",
    "                                          'Weighted_f1': across_fold_Wf1s[best_dictionary[model_name][0]],\n",
    "                                          'Avg_f1': f1s[best_dictionary[model_name][0]]}\n",
    "        model_names = []\n",
    "        Unweighted_f1 = []\n",
    "        Weighted_f1 = []\n",
    "        Avg_f1 = []\n",
    "        print('2')\n",
    "        for model_name in best_dictionary:\n",
    "            model_names.append(model_names)\n",
    "            Unweighted_f1.append(best_dictionary[model_name]['Unweighted_f1'])\n",
    "            Weighted_f1.append(best_dictionary[model_name]['Weighted_f1'])\n",
    "            Avg_f1.append(best_dictionary[model_name]['Avg_f1'])\n",
    "        print('3')\n",
    "        df = pd.DataFrame({'Model': model_names, 'Unweighted_f1score': Unweighted_f1, \n",
    "                           'Weighted_f1score':Weighted_f1, 'Avg_f1score': Avg_f1})\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = compare_classifiers(X,Y,n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "[  1   3   4   5   6   7   8  10  12  13  14  15  16  17  19  20  21  23\n",
      "  24  25  26  27  29  31  32  33  35  36  38  39  40  41  43  44  45  48\n",
      "  49  50  51  52  53  54  55  56  58  59  60  61  62  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  80  81  82  83  84  85  86  87  88\n",
      "  89  91  92  93  94  95  96  97  98  99 100 102 104 105 106 108 109 110\n",
      " 112 113 115 116 117 118 119 120 121 123 125 126 127 128 129 130 131 132\n",
      " 133 134 137 138 139 141 142 143 144 146 147 149 150 152 153 154 155 156\n",
      " 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174\n",
      " 175 176 177 179 180 182 184 185 186 187 188 189 190 191 193 194 196 197\n",
      " 198 199 201 203 204 205 206 207 208 209 211 212 213 214 215 216 217 219\n",
      " 221 222 223 225 226 227 229 230 232 234 235 236 237 238 239 240 241 242\n",
      " 245 246 248 249 250 252 253 254 255 256 257 258 260 261 262 263 264 265\n",
      " 266 268 269 274 276 277 278 279 280 281 282 283 285 286 288 289 290 291\n",
      " 292 294 295 296 297 298 300 301 302 303 305 306 307 308 309 311 312 314\n",
      " 315 317 318 319 320 321 324 325 326 327 328 330 333 334 335 336 337 338\n",
      " 339 340 341 343 344 345 346 347 349 350 351 352 353 354 355 356 357 358\n",
      " 359 361 362 364 365 366 367 368 369 370 372 373 374 376 378 380 381 382\n",
      " 383 384 385 387 388 389 390 392 393 394 395 397 398 399 400 401 402 404\n",
      " 405 406 407 408 409 410 412 413 414 418 420 421 422 423 424 425 426 427\n",
      " 428 429 431 432 433 435 436 437 439 440 441]\n",
      "[  0   2   9  11  18  22  28  30  34  37  42  46  47  57  63  64  79  90\n",
      " 101 103 107 111 114 122 124 135 136 140 145 148 151 178 181 183 192 195\n",
      " 200 202 210 218 220 224 228 231 233 243 244 247 251 259 267 270 271 272\n",
      " 273 275 284 287 293 299 304 310 313 316 322 323 329 331 332 342 348 360\n",
      " 363 371 375 377 379 386 391 396 403 411 415 416 417 419 430 434 438]\n",
      "begin_training\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.01, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.01, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.1, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.1, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 1, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 1, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 10, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 10, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 100, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 100, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_linear\n",
      "{'C': 0.01}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_linear\n",
      "{'C': 0.1}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_linear\n",
      "{'C': 1}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_linear\n",
      "{'C': 10}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_linear\n",
      "{'C': 100}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_rbf\n",
      "{'C': 0.01}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_rbf\n",
      "{'C': 0.1}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_rbf\n",
      "{'C': 1}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_rbf\n",
      "{'C': 10}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "SVM_rbf\n",
      "{'C': 100}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'gini', 'max_depth': 4}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'gini', 'max_depth': 12}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'gini', 'max_depth': 16}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'gini', 'max_depth': 24}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'entropy', 'max_depth': 4}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'entropy', 'max_depth': 12}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'entropy', 'max_depth': 16}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "RandomForest\n",
      "{'criterion': 'entropy', 'max_depth': 24}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "GaussianNB\n",
      "None\n",
      "after fitting\n",
      "after predicting\n",
      "[[0.0, 0.0010327999092044036, 0.0, 0.0012244897959183673, 0.0, 0.009009009009009009, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004975124378109453, 0.00505050505050505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005333333333333333, 0.009333333333333332, 0.0024509803921568627]]\n",
      "[[0.0, 0.0010327999092044036, 0.0, 0.0012520064205457462, 0.0, 0.011235955056179775, 0.0, 0.0, 0.0, 0.0, 0.00149812734082397, 0.00149812734082397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007490636704119849, 0.007490636704119849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007490636704119849, 0.013108614232209737, 0.0028089887640449437]]\n",
      "fold: 1\n",
      "[  0   1   2   3   5   7   8   9  10  11  12  14  16  18  19  21  22  23\n",
      "  24  26  28  29  30  31  32  33  34  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  53  55  56  57  58  60  61  63  64  65  66\n",
      "  67  70  72  73  74  76  77  79  80  81  82  83  84  86  87  88  89  90\n",
      "  92  94  95  97 100 101 102 103 106 107 108 110 111 112 113 114 115 116\n",
      " 117 118 119 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 143 145 146 147 148 149 150 151 152 153 155 156\n",
      " 157 158 159 160 162 163 164 165 166 167 169 171 172 173 174 176 177 178\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 198 199 200\n",
      " 201 202 203 204 205 207 209 210 211 213 215 217 218 219 220 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 236 237 239 241 242 243 244 246\n",
      " 247 249 250 251 253 254 256 257 258 259 260 261 263 264 265 266 267 268\n",
      " 269 270 271 272 273 275 276 277 278 279 280 281 283 284 285 286 287 289\n",
      " 290 291 292 293 295 296 297 298 299 300 301 302 303 304 305 307 308 309\n",
      " 310 311 312 313 314 315 316 318 319 321 322 323 324 325 326 327 328 329\n",
      " 330 331 332 333 334 335 337 339 340 341 342 343 344 345 346 347 348 349\n",
      " 350 355 357 359 360 361 362 363 364 365 367 369 371 372 373 374 375 377\n",
      " 379 380 382 384 385 386 387 388 390 391 392 394 395 396 397 399 401 402\n",
      " 403 404 406 407 408 409 410 411 415 416 417 419 420 421 422 423 424 425\n",
      " 426 427 429 430 431 432 433 434 436 437 438]\n",
      "[  4   6  13  15  17  20  25  27  35  52  54  59  62  68  69  71  75  78\n",
      "  85  91  93  96  98  99 104 105 109 120 142 144 154 161 168 170 175 179\n",
      " 180 196 197 206 208 212 214 216 221 235 238 240 245 248 252 255 262 274\n",
      " 282 288 294 306 317 320 336 338 351 352 353 354 356 358 366 368 370 376\n",
      " 378 381 383 389 393 398 400 405 412 413 414 418 428 435 439 440 441]\n",
      "begin_training\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.01, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.01, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.1, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 0.1, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 1, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 1, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 10, 'solver': 'lbfgs'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 10, 'solver': 'liblinear'}\n",
      "after fitting\n",
      "after predicting\n",
      "fit model\n",
      "Logistic\n",
      "{'C': 100, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "a.fit_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa(kwangs):\n",
    "    print(kwangs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 10}\n"
     ]
    }
   ],
   "source": [
    "a= {'kernel': 'rbf', 'gamma':  10}\n",
    "aaa(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kamin/Thai_NLP'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_123.pkl','rb') as f:\n",
    "    out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1s': {'negative': 0.7557251908396946,\n",
       "  'neutral': 0.7948717948717949,\n",
       "  'positive': 0.9324324324324325},\n",
       " 'weighted_f1': 0.8095179353769782,\n",
       " 'unweighted_f1': 0.8276764727146406,\n",
       " 'conf_mat': array([[ 99,  30,   3],\n",
       "        [ 29, 124,   0],\n",
       "        [  2,   5,  69]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
