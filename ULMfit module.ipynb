{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.callbacks import CSVLogger, SaveModelCallback\n",
    "from pythainlp.ulmfit import *\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from fastai.utils.mem import GPUMemTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6770ab9c0c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvalid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = \".\"\n",
    "\n",
    "train_df = tr \n",
    "valid_df = te\n",
    "all_df = pd.concat((tr,te))\n",
    "\n",
    "tt = Tokenizer(tok_func=ThaiTokenizer, lang=\"th\", pre_rules=pre_rules_th, post_rules=post_rules_th)\n",
    "processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=None, max_vocab=60000, min_freq=2)]\n",
    "\n",
    "data_lm = (TextList.from_df(all_df, model_path, cols=\"texts\", processor=processor)\n",
    "    .split_by_rand_pct(valid_pct = 0.2, seed = 1412)\n",
    "    .label_for_lm()\n",
    "    .databunch(bs=48))\n",
    "data_lm.sanity_check()\n",
    "data_lm.save('test_lm.pkl')\n",
    "print(len(data_lm.train_ds))\n",
    "print(len(data_lm.valid_ds))\n",
    "\n",
    "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False, tie_weights=True, out_bias=True,\n",
    "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
    "\n",
    "trn_args = dict(drop_mult=1., clip=0.12, alpha=2, beta=1)\n",
    "\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "\n",
    "#load pretrained models\n",
    "learn.load_pretrained(**_THWIKI_LSTM)\n",
    "\n",
    "#train unfrozen\n",
    "print(\"training unfrozen\")\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(6, 1e-3, moms=(0.8, 0.7))\n",
    "\n",
    "learn.save_encoder('CS_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(model_path, \"test_lm.pkl\")\n",
    "data_lm.sanity_check()\n",
    "\n",
    "#classification data\n",
    "tt = Tokenizer(tok_func=ThaiTokenizer, lang=\"th\", pre_rules=pre_rules_th, post_rules=post_rules_th)\n",
    "processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=data_lm.vocab, max_vocab=60000, min_freq=20)]\n",
    "\n",
    "data_cls = (ItemLists(model_path,train=TextList.from_df(tr, model_path, cols=[\"texts\"], processor=processor),\n",
    "                     valid=TextList.from_df(te, model_path, cols=[\"texts\"], processor=processor))\n",
    "    .label_from_df(\"labels\")\n",
    "    .databunch(bs=50)\n",
    "    )\n",
    "data_cls.sanity_check()\n",
    "print(len(data_cls.vocab.itos))\n",
    "\n",
    "#model\n",
    "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False,\n",
    "             output_p=0.4, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "trn_args = dict(bptt=70, drop_mult=0.7, alpha=2, beta=1, max_len=500)\n",
    "\n",
    "learn = text_classifier_learner(data_cls, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "#load pretrained finetuned model\n",
    "learn.load_encoder(\"CS_enc\")\n",
    "\n",
    "#train unfrozen\n",
    "learn.freeze_to(-1)\n",
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))\n",
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\n",
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3 / (2.6 ** 4), 5e-3), moms=(0.8, 0.7))\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, slice(1e-3 / (2.6 ** 4), 1e-3), moms=(0.8, 0.7),\n",
    "                   callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', name='bestmodel')])\n",
    "\n",
    "learn.load(\"bestmodel\")\n",
    "\n",
    "#get predictions\n",
    "probs, y_true, loss = learn.get_preds(ds_type = DatasetType.Valid, ordered=True, with_loss=True)\n",
    "classes = learn.data.train_ds.classes\n",
    "y_true = np.array([classes[i] for i in y_true.numpy()])\n",
    "preds = np.array([classes[i] for i in probs.argmax(1).numpy()])\n",
    "prob = probs.numpy()\n",
    "loss = loss.numpy()\n",
    "\n",
    "to_df = np.concatenate([y_true[:,None],preds[:,None],loss[:,None],prob],1)\n",
    "probs_df = pd.DataFrame(to_df)\n",
    "probs_df.columns = [\"category\",\"preds\",\"loss\"] + classes\n",
    "probs_df[\"hit\"] = (probs_df.category == probs_df.preds)\n",
    "probs_df[\"texts\"] = valid_df.texts\n",
    "(y_true==preds).mean()\n",
    "\n",
    "conf_mat = confusion_matrix(probs_df.category,probs_df.preds)\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\",\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks.tracker import TrackerCallback, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveEncoderCallback(TrackerCallback):\n",
    "    \"A `TrackerCallback` that saves the model when monitored quantity is best.\"\n",
    "    def __init__(self, learn:Learner, monitor:str='valid_loss', mode:str='auto', every:str='improvement', name:str='bestmodel'):\n",
    "        super().__init__(learn, monitor=monitor, mode=mode)\n",
    "        self.every,self.name = every,name\n",
    "        if self.every not in ['improvement', 'epoch']:\n",
    "            warn(f'SaveModel every {self.every} is invalid, falling back to \"improvement\".')\n",
    "            self.every = 'improvement'\n",
    "\n",
    "    def jump_to_epoch(self, epoch:int)->None:\n",
    "        try:\n",
    "            self.learn.load(f'{self.name}_{epoch-1}', purge=False)\n",
    "            print(f\"Loaded {self.name}_{epoch-1}\")\n",
    "        except: print(f'Model {self.name}_{epoch-1} not found.')\n",
    "\n",
    "    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n",
    "        \"Compare the value monitored to its best score and maybe save the model.\"\n",
    "        if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\n",
    "        else: #every=\"improvement\"\n",
    "            current = self.get_monitor_value()\n",
    "            if isinstance(current, Tensor): current = current.cpu()\n",
    "            if current is not None and self.operator(current, self.best):\n",
    "                print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\n",
    "                self.best = current\n",
    "                self.learn.save_encoder(f'{self.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ULMfit_for_predict():\n",
    "    def __init__(self,\n",
    "                 model_path):\n",
    "        data_lm = load_data(model_path, \"language_model_data.pkl\")\n",
    "        data_lm.sanity_check()\n",
    "        cur_path = os.getcwd()\n",
    "        os.chdir(model_path)\n",
    "        tr = pd.read_csv('train.csv')\n",
    "        te = pd.read_csv('test.csv')\n",
    "        os.chdir(cur_path)\n",
    "        #classification data\n",
    "        tt = Tokenizer(tok_func=ThaiTokenizer, lang=\"th\", pre_rules=pre_rules_th, post_rules=post_rules_th)\n",
    "        processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "                    NumericalizeProcessor(vocab=data_lm.vocab, max_vocab=60000, min_freq=20)]\n",
    "\n",
    "        data_cls = (ItemLists(model_path,train=TextList.from_df(tr, model_path, cols=[\"texts\"], processor=processor),\n",
    "                             valid=TextList.from_df(te, model_path, cols=[\"texts\"], processor=processor))\n",
    "            .label_from_df(\"labels\")\n",
    "            .databunch(bs=50)\n",
    "            )\n",
    "        data_cls.sanity_check()\n",
    "#         print(len(data_cls.vocab.itos))\n",
    "\n",
    "        config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False,\n",
    "                     output_p=0.4, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "        trn_args = dict(bptt=70, drop_mult=0.7, alpha=2, beta=1, max_len=500)\n",
    "\n",
    "        self.learn = text_classifier_learner(data_cls, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "        self.learn.load(\"bestmodel\")\n",
    "        self.classes = self.learn.data.train_ds.classes\n",
    "    def predict(self,\n",
    "                raw_text):\n",
    "        dictionary = {}\n",
    "        x = self.learn.predict(raw_text)[2].numpy()\n",
    "        for ind, tmp_class in enumerate(self.classes):\n",
    "            dictionary[tmp_class] = x[ind]\n",
    "        return dictionary\n",
    "    \n",
    "class ULMfit_model():\n",
    "    # to train using ULMfit\n",
    "    # 1. Fine-tuning the language model is needed\n",
    "    # 2. Train the classifier\n",
    "    def __init__(self,\n",
    "                 data_for_lm, \n",
    "                 model_path: '(str) locate to the folder dont specify in any extension'):\n",
    "        self.model_path = model_path\n",
    "        self.tt = Tokenizer(tok_func=ThaiTokenizer, lang=\"th\", pre_rules=pre_rules_th, post_rules=post_rules_th)\n",
    "        self.processor = [TokenizeProcessor(tokenizer=self.tt, chunksize=10000, mark_fields=False),\n",
    "                    NumericalizeProcessor(vocab=None, max_vocab=60000, min_freq=2)]\n",
    "        \n",
    "        self.data_lm = (TextList.from_df(data_for_lm, self.model_path, cols=\"texts\", processor=self.processor)\n",
    "            .split_by_rand_pct(valid_pct = 0.2, seed = 123)\n",
    "            .label_for_lm()\n",
    "            .databunch(bs=48))\n",
    "        self.data_lm.save('language_model_data.pkl')\n",
    "        self.data_lm.sanity_check()\n",
    "        print(f'number of training samples: {len(self.data_lm.train_ds)}')\n",
    "        print(f'number of test samples: {len(self.data_lm.valid_ds)}')\n",
    "        self.learn = None\n",
    "        \n",
    "    def fit_lm(self):\n",
    "        config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False, tie_weights=True, out_bias=True,\n",
    "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
    "\n",
    "        trn_args = dict(drop_mult=1., clip=0.12, alpha=2, beta=1)\n",
    "\n",
    "        self.learn = language_model_learner(self.data_lm, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "\n",
    "        #load pretrained models\n",
    "        self.learn.load_pretrained(**_THWIKI_LSTM)\n",
    "\n",
    "        #train unfrozen\n",
    "        print(\"training unfrozen\")\n",
    "#         with GPUMemTrace():\n",
    "        self.learn.unfreeze()\n",
    "\n",
    "        self.learn.fit_one_cycle(3, 1e-3, moms=(0.8, 0.7),\n",
    "                                 callbacks=[SaveEncoderCallback(self.learn, every='improvement', monitor='accuracy', name='LM'),\n",
    "                                            EarlyStoppingCallback(self.learn, min_delta=0.0, patience=5)])\n",
    "    def fit_classifier(self,\n",
    "                       tr,\n",
    "                       te):\n",
    "        self.processor = [TokenizeProcessor(tokenizer=self.tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=self.data_lm.vocab, max_vocab=60000, min_freq=20)]\n",
    "\n",
    "        self.data_cls = (ItemLists(self.model_path,train=TextList.from_df(tr, self.model_path, cols=[\"texts\"], processor=self.processor),\n",
    "                             valid=TextList.from_df(te, self.model_path, cols=[\"texts\"], processor=self.processor))\n",
    "            .label_from_df(\"labels\")\n",
    "            .databunch(bs=50)\n",
    "            )\n",
    "        tr.to_csv(os.path.join(self.model_path, 'train.csv'), index=False)\n",
    "        te.to_csv(os.path.join(self.model_path, 'test.csv'), index=False)\n",
    "#         self.data_cls.save('data_cls.pkl')\n",
    "        self.data_cls.sanity_check()\n",
    "        print(f'total vocab size: {len(self.data_cls.vocab.itos)}')\n",
    "\n",
    "        #model\n",
    "        config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False,\n",
    "                     output_p=0.4, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "        trn_args = dict(bptt=70, drop_mult=0.7, alpha=2, beta=1, max_len=500)\n",
    "\n",
    "        self.learn = text_classifier_learner(self.data_cls, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "        #load pretrained finetuned model\n",
    "        self.learn.load_encoder(\"./LM\")\n",
    "\n",
    "        #train unfrozen\n",
    "#         with GPUMemTrace():\n",
    "        self.learn.freeze_to(-1)\n",
    "        self.learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))\n",
    "        self.learn.freeze_to(-2)\n",
    "        self.learn.fit_one_cycle(1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\n",
    "        self.learn.freeze_to(-3)\n",
    "        self.learn.fit_one_cycle(1, slice(5e-3 / (2.6 ** 4), 5e-3), moms=(0.8, 0.7))\n",
    "        self.learn.unfreeze()\n",
    "        self.learn.fit_one_cycle(3, slice(1e-3 / (2.6 ** 4), 1e-3), moms=(0.8, 0.7),\n",
    "                           callbacks=[SaveModelCallback(self.learn, every='improvement', monitor='accuracy', name='bestmodel'),\n",
    "                                      EarlyStoppingCallback(self.learn, min_delta=0.0, patience=5)])\n",
    "\n",
    "        self.learn.load(\"bestmodel\")\n",
    "\n",
    "        #get predictions\n",
    "        probs, y_true, loss = self.learn.get_preds(ds_type = DatasetType.Valid, ordered=True, with_loss=True)\n",
    "        classes = self.learn.data.train_ds.classes\n",
    "        y_true = np.array([classes[i] for i in y_true.numpy()])\n",
    "        preds = np.array([classes[i] for i in probs.argmax(1).numpy()])\n",
    "        prob = probs.numpy()\n",
    "        loss = loss.numpy()\n",
    "\n",
    "        to_df = np.concatenate([y_true[:,None],preds[:,None],loss[:,None],prob],1)\n",
    "        probs_df = pd.DataFrame(to_df)\n",
    "        probs_df.columns = [\"category\",\"preds\",\"loss\"] + classes\n",
    "        probs_df[\"hit\"] = (probs_df.category == probs_df.preds)\n",
    "        probs_df[\"texts\"] = te.texts\n",
    "        (y_true==preds).mean()\n",
    "\n",
    "        conf_mat = confusion_matrix(probs_df.category,probs_df.preds)\n",
    "        sns.heatmap(conf_mat, annot=True, fmt=\"d\",\n",
    "                    xticklabels=classes, yticklabels=classes)\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.show()\n",
    "        \n",
    "        f1s = f1_score(probs_df.category, probs_df.preds, average=None)\n",
    "        print(f'f1-scores for each class: {f1s}')\n",
    "        print(f'Weighted avg f1-score: {f1_score(probs_df.category, probs_df.preds, average=\"weighted\")}, Unweighted avf f1-score: {np.mean(f1s)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kamin'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('train_RS_123.csv')\n",
    "# tr.head()\n",
    "te = pd.read_csv('test_RS_123.csv')\n",
    "# te.head()\n",
    "tr = tr.dropna().reset_index(drop=True)\n",
    "te = te.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BAY_pantip.json', 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in data:\n",
    "    i = data[i].strip()\n",
    "    if i != '':\n",
    "        i = i.split('\\n')\n",
    "        for j in i:\n",
    "            j = j.strip()\n",
    "            if j != '':\n",
    "                tmp.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121111"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จ่ายเงินเฟิสช้อยขาด\n",
      "จ่ายเฟิร์สช้อยขาดไป 60 บาท เป็นอะไรมั้ยค่ะ\n",
      "โดนดอกเบี้ยสิจ๊ะ นับตั้งแต่วันที่รูดนะไม่ใช่วันที่จ่ายแล้วขาด60บาท\n",
      "รีบจ่ายให้ครบก่อนเกินกำหนด ไม่งั้นจะโดนคิดดอกเบี้ย\n",
      "โดนดอกเบี้ยสิจ๊ะ นับตั้งแต่วันที่รูดนะไม่ใช่วันที่จ่ายแล้วขาด60บาท\n",
      "รีบไปจ่ายเลยจ้าไม่งั้นโดนดอกเพื่ม\n",
      "ไม่เป็นไร เพราะ สมมุติจ่ายขาดไป 60 บาท จากยอดรูดทั้งหมดในรอบบิลนั้น 10,000 บาท จะโดนคิดดอก18% ทุกรายการจากยอด 10,000 ไม่ใช่ 60 บาท\n",
      "ไม่งงนะ\n",
      "สวัสดีครับ คุณสมาชิกหมายเลข 4217582\n",
      "อย่างไรแล้วทางเจ้าหน้าที่ขอทราบชื่อ - นามสกุล เบอร์ติดต่อ พร้อมแนบ link กระทู้นี้ให้เจ้าหน้าทางหลังไมค์ด้วยครับ เจ้าหน้าที่จะได้ตรวจสอบข้อมูล และ แจ้งรายละเอียดให้ทราบโดยตรง\n",
      "ขอบคุณครับ\n",
      "กดแอพธนาคารในโทรศัพท์แล้วกดจ่ายเพิ่มเข้าไปอีก 60 บาทค่ะไม่งั้นบิลหน้มีดอกเบี้ยโผล่มาให้ตกใจอีกนะคะ\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(tmp):\n",
    "    print(i)\n",
    "    if ind > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = list(set(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [i.strip() for i in tmp if len(i.strip()) >= 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [len(i) for i in tmp]\n",
    "plt.hist(x,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.92135055012832"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sorted(x, reverse=True)\n",
    "y = y[int(len(y)*0.01):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_lm = pd.DataFrame({'texts': tmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Thai_NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ulmfit import ULMfit_for_predict, ULMfit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples: 80\n",
      "number of test samples: 20\n"
     ]
    }
   ],
   "source": [
    "model_path = './Untitled Folder 1'\n",
    "model = ULMfit_model(tr.iloc[:100], model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training unfrozen\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.617828</td>\n",
       "      <td>3.285137</td>\n",
       "      <td>0.293452</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.565338</td>\n",
       "      <td>2.688225</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.302119</td>\n",
       "      <td>2.575235</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.2934523820877075.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 1 with accuracy value: 0.4476190507411957.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 2 with accuracy value: 0.4702380895614624.\n"
     ]
    }
   ],
   "source": [
    "model.fit_lm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab size: 112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.246212</td>\n",
       "      <td>1.063404</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.225631</td>\n",
       "      <td>1.034198</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.978192</td>\n",
       "      <td>1.046586</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.952645</td>\n",
       "      <td>1.039602</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.925124</td>\n",
       "      <td>1.031824</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>1.029545</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.49000000953674316.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-scores for each class: [0.254545 0.605042 0.461538]\n",
      "Weighted avg f1-score: 0.45510254451430926, Unweighted avf f1-score: 0.44037531096354626\n"
     ]
    }
   ],
   "source": [
    "model.fit_classifier(tr.iloc[:100],te.iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ULMfit_for_predict(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [31:47<00:00,  5.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 52min 29s, sys: 51.2 s, total: 1h 53min 20s\n",
      "Wall time: 31min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in trange(10000):\n",
    "    x.predict(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Thai_NLP')\n",
    "from text_classification import Text_classification_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading logistic regression model\n"
     ]
    }
   ],
   "source": [
    "tc = Text_classification_for_prediction(\n",
    "    path_to_tfxidf = 'models_for_real_deployment/tf-idf_encoder.joblib',\n",
    "    model_path= 'models_for_real_deployment/text_classification',\n",
    "    engine = \"linear_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 913.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 70.6 ms, total: 11.3 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in trange(10000):\n",
    "    tc.predict(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, BertModel, TFBertForPreTraining, BertForPreTraining\n",
    "import sentencepiece as spm\n",
    "\n",
    "VOCAB_DIR = '../th_wiki_bpe/th.wiki.bpe.op25000.vocab'\n",
    "MODEL_DIR = '../th_wiki_bpe/th.wiki.bpe.op25000.model'\n",
    "\n",
    "class InputFeatures():\n",
    "    def __init__(self,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = input_mask\n",
    "        self.token_type_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "class ThaiTokenizer():\n",
    "    def __init__(self,\n",
    "               model_dir,\n",
    "               vocab_dir):\n",
    "        #<unk> ==> ind = 4\n",
    "        self.dictionary = {}\n",
    "        with open(vocab_dir, 'r', encoding='utf8') as f:\n",
    "            for ind,i in enumerate(f):\n",
    "                self.dictionary[i.split()[0]] = ind\n",
    "        self.sp = spm.SentencePieceProcessor(model_file=model_dir)\n",
    "    def tokenize(self,\n",
    "                text):\n",
    "        return self.sp.encode(text, out_type=str)\n",
    "    def convert_tokens_to_ids(self,\n",
    "                            tokens):\n",
    "        tmp = []\n",
    "        for i in tokens:\n",
    "            try:\n",
    "                tmp.append(self.dictionary[i])\n",
    "            except:\n",
    "                tmp.append(4)\n",
    "        return tmp\n",
    "    \n",
    "\n",
    "class Text_classification_examples():\n",
    "    def __init__(self, tokenizer, max_len, ulabels):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.ulabels = ulabels\n",
    "\n",
    "    def preprocess(self,\n",
    "                  texts,\n",
    "                  labels=None):\n",
    "#         print(labels)\n",
    "        if labels is not None:\n",
    "            assert len(texts) == len(labels), 'len(texts) != len(labels)'\n",
    "        dataset_dict = {\n",
    "            \"input_ids\": [],\n",
    "            \"token_type_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"label_onehot\": [],\n",
    "        }\n",
    "        for i in range(len(texts)):\n",
    "            if labels is not None:\n",
    "                feature_obj = self.convert_single_example(i, texts[i], labels[i])\n",
    "            else:\n",
    "                feature_obj = self.convert_single_example(i, texts[i])\n",
    "            for feature in dataset_dict:\n",
    "                if feature == 'label_onehot':\n",
    "                    if labels is not None:\n",
    "                        dataset_dict['label_onehot'].append(getattr(feature_obj, 'label_id'))\n",
    "                    else:\n",
    "                        dataset_dict['label_onehot'].append(None)\n",
    "                else:\n",
    "                    dataset_dict[feature].append(getattr(feature_obj, feature))\n",
    "        return [dataset_dict[\"input_ids\"], dataset_dict[\"token_type_ids\"], dataset_dict[\"attention_mask\"]], [dataset_dict[\"label_onehot\"]]\n",
    "\n",
    "    def convert_single_example(self, \n",
    "                             ex_index, \n",
    "                             text_a, \n",
    "                             label=None):\n",
    "        \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "        tokens_a = self.tokenizer.tokenize(text_a)\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens_a) > self.max_len - 2:\n",
    "            tokens_a = tokens_a[:(self.max_len - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0     0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = []\n",
    "        segment_ids = []\n",
    "        tokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        for token in tokens_a:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < self.max_len:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "        # print(len(input_ids))\n",
    "        # print(len(input_mask))\n",
    "        # print(len(segment_ids))\n",
    "        assert len(input_ids) == self.max_len\n",
    "        assert len(input_mask) == self.max_len\n",
    "        assert len(segment_ids) == self.max_len\n",
    "        if label is not None:\n",
    "            label_id = self.ulabels[label]\n",
    "        else:\n",
    "            label_id = -1\n",
    "#         if ex_index < 5:\n",
    "#             print(\"*** Example ***\")\n",
    "#             print(\"tokens: %s\" % \" \".join(tokens))\n",
    "#             print(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "#             print(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "#             print(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "#             print(\"label: %s (id = %d)\" % (label, label_id))\n",
    "\n",
    "        feature = InputFeatures(\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            segment_ids=segment_ids,\n",
    "            label_id=label_id)\n",
    "        return feature\n",
    "    \n",
    "tokenizer = ThaiTokenizer(MODEL_DIR, VOCAB_DIR)\n",
    "max_len = 128\n",
    "ulabels = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "data_preb = Text_classification_examples(tokenizer, max_len, ulabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,Y =data_preb.preprocess(tmp[:10000])#, tr['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file('../bert_base_th/bert_config.json')\n",
    "# encoder = BertForPreTraining.from_pretrained('./bert_base_th/model.ckpt',from_tf=True, config=config)\n",
    "# encoder = BertForPreTraining.from_pretrained('./BERTLM_fold1.pt', config=config)\n",
    "encoder = torch.load('../BERTLM_fold1.pt')\n",
    "class bert_for_classification(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        BertForPreTraining_model: '(transformers obj)',\n",
    "        unique_labels: '(dict[str:int]) the keys are unique labels, the values are integers mapping to class index (from 0 to num_unique_labels - 1)',\n",
    "        max_len: '(int) max length of the input sequences'):\n",
    "        super().__init__()\n",
    "        self.BertForPreTraining_model = BertForPreTraining_model\n",
    "        self.unique_labels = unique_labels\n",
    "        self.max_len = max_len\n",
    "        self.linear1 = torch.nn.Linear(768, 2)\n",
    "#         self.linear1 = torch.nn.Linear(768, 256)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.out = torch.nn.Linear(256, len(self.unique_labels))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        input_ids = inputs[0]\n",
    "        token_type_ids = inputs[1]\n",
    "        attention_mask = inputs[2]\n",
    "        x = self.BertForPreTraining_model.bert(input_ids, token_type_ids, attention_mask)[0]\n",
    "        x = F.gelu((self.linear1(x)))\n",
    "        x = self.flatten(x)\n",
    "        return self.out(x)\n",
    "#.220\n",
    "BERT = bert_for_classification(BertForPreTraining_model= encoder, \n",
    "                               unique_labels= {'negative': 0, 'neutral': 1, 'positive': 2}, \n",
    "                               max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "BS = 32\n",
    "remainder_te = False\n",
    "num_te = len(tmp)//BS\n",
    "if len(tmp)%BS != 0:\n",
    "    remainder_te = True\n",
    "NUM_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now is epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3141/3141 [2:19:25<00:00,  2.66s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 9min 45s, sys: 28.6 s, total: 9h 10min 14s\n",
      "Wall time: 2h 19min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(NUM_EPOCH):\n",
    "    print(f'now is epoch: {i}')\n",
    "    with torch.no_grad():\n",
    "        for j in trange(num_te):\n",
    "            data, _ = data_preb.preprocess(tmp[BS*j: BS*(j+1)])\n",
    "            data1 = torch.tensor(data[0],dtype=torch.int64).to(device)\n",
    "            data2 = torch.tensor(data[1],dtype=torch.int64).to(device)\n",
    "            data3 = torch.tensor(data[2],dtype=torch.int64).to(device)\n",
    "#             target = y_te[BS*j: BS*(j+1)].to(device)\n",
    "\n",
    "            out = BERT([data1, data2, data3])\n",
    "#             loss = criterion(out, target)\n",
    "#             tmp_loss += loss.item()\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "        if remainder_te:\n",
    "            data, _ = data_preb.preprocess(tmp[BS*(j+1):])\n",
    "            data1 = torch.tensor(data[0],dtype=torch.int64).to(device)\n",
    "            data2 = torch.tensor(data[1],dtype=torch.int64).to(device)\n",
    "            data3 = torch.tensor(data[2],dtype=torch.int64).to(device)\n",
    "#             target = y[BS*(j+1):].to(device)\n",
    "\n",
    "            out = BERT([data1, data2, data3])\n",
    "    #         target = torch.max(target, 1)\n",
    "    #         out = torch.max(out, 1)\n",
    "#             loss = criterion(out, target)\n",
    "#             tmp_loss += loss.item()\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
