{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import pythainlp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Word_Embedder\n",
    "from preprocessing import Text_processing\n",
    "from text_classification import Text_classification, Text_classification_for_prediction, count_based_model\n",
    "from text_classification import prepare_data_for_text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kamin/Thai_NLP'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('Thai_NLP')\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'word_configs\\\\pos.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c74953403636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mis_sentiment_analysis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mdo_load_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                       model_path= 'trained_models')\n\u001b[0m",
      "\u001b[0;32m~/Thai_NLP/text_classification.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename_dict, is_sentiment_analysis, do_load_models, model_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_class\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtmp_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'word_configs\\\\pos.txt'"
     ]
    }
   ],
   "source": [
    "x = count_based_model({'pos': ['word_configs\\\\pos.txt', 'word_configs\\\\pos_manual.txt'], 'neg': ['word_configs\\\\neg.txt', 'word_configs\\\\neg_manual.txt'], 'neu': ['word_configs\\\\neu.txt'],\n",
    "                      'q': ['word_configs\\\\q.txt', 'word_configs\\\\q_manual.txt']},\n",
    "                      is_sentiment_analysis=True, \n",
    "                      do_load_models=True, \n",
    "                      model_path= 'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running grid search and 5-folds cross validation\n",
      "best_C: 1, f1-score: [0.55146125 0.27612761 0.3853211  0.14197531], f1-macro: 0.3387213168889381\n"
     ]
    }
   ],
   "source": [
    "x.fit(Tr,Te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.predict('ไม่อร่อยเลย ไม่ดีอะ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.predict('อร่อยดีนะ ชอบมากอะ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wisesight sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Sentiment Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = []\n",
    "with open('train.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            tr.append(line)\n",
    "            \n",
    "tr_label = []\n",
    "with open('train_label.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            tr_label.append(line)\n",
    "            \n",
    "te = []\n",
    "with open('test.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            te.append(line)\n",
    "            \n",
    "te_label = []\n",
    "with open('test_label.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            te_label.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr = pd.DataFrame({'texts': tr, 'labels': tr_label})\n",
    "Te = pd.DataFrame({'texts': te, 'labels': te_label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRUE-intent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kamin/Thai_NLP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('Thai_NLP')\n",
    "os.getcwd()\n",
    "# os.listdir()'/home/kamin/Thai_NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('kamin/Thai_NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>texts_deepcut</th>\n",
       "      <th>action</th>\n",
       "      <th>object</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สอบถาม package internet ว่ามีแบบไหนบ้างครับ</td>\n",
       "      <td>สอบถาม package internet ว่า มี แบบ ไหน บ้าง ครับ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>promotion</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>พอดีพี่ซื้อเบอร์ซิม Inter ไปแล้ว แต่ยังไม่ได้ล...</td>\n",
       "      <td>พอดี พี่ ซื้อ เบอร์ซิม Inter ไป แล้ว แต่ ยัง ไ...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>detail</td>\n",
       "      <td>billing and payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ค่ะ พี่ค่ะ คืออยู่ๆ เน็ตเล่นไม่ได้อ่ะค่ะ</td>\n",
       "      <td>ค่ะ พี่ ค่ะ คือ อยู่ ๆ เน็ต เล่น ไม่ ได้ อ่ะ ค่ะ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>internet</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>การเปลี่ยน ระบบจาก ทรู เป็น ทรูเอช มีค่าบริการ...</td>\n",
       "      <td>การ เปลี่ยน ระบบ จาก ทรู เป็น ทรูเอช มี ค่า บร...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>rate</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>เช็คให้หน่อยได้ไหมครับ ว่าเบอร์ของผม เปลี่ยนเป...</td>\n",
       "      <td>เช็ค ให้ หน่อย ได้ ไหม ครับ ว่า เบอร์ ของ ผม เ...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>package</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  \\\n",
       "0        สอบถาม package internet ว่ามีแบบไหนบ้างครับ   \n",
       "1  พอดีพี่ซื้อเบอร์ซิม Inter ไปแล้ว แต่ยังไม่ได้ล...   \n",
       "2           ค่ะ พี่ค่ะ คืออยู่ๆ เน็ตเล่นไม่ได้อ่ะค่ะ   \n",
       "3  การเปลี่ยน ระบบจาก ทรู เป็น ทรูเอช มีค่าบริการ...   \n",
       "4  เช็คให้หน่อยได้ไหมครับ ว่าเบอร์ของผม เปลี่ยนเป...   \n",
       "\n",
       "                                       texts_deepcut   action     object  \\\n",
       "0   สอบถาม package internet ว่า มี แบบ ไหน บ้าง ครับ  enquire  promotion   \n",
       "1  พอดี พี่ ซื้อ เบอร์ซิม Inter ไป แล้ว แต่ ยัง ไ...  enquire     detail   \n",
       "2   ค่ะ พี่ ค่ะ คือ อยู่ ๆ เน็ต เล่น ไม่ ได้ อ่ะ ค่ะ  enquire   internet   \n",
       "3  การ เปลี่ยน ระบบ จาก ทรู เป็น ทรูเอช มี ค่า บร...  enquire       rate   \n",
       "4  เช็ค ให้ หน่อย ได้ ไหม ครับ ว่า เบอร์ ของ ผม เ...  enquire    package   \n",
       "\n",
       "           destination  \n",
       "0           promotions  \n",
       "1  billing and payment  \n",
       "2             internet  \n",
       "3           promotions  \n",
       "4           promotions  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mari-train-balanced.csv')\n",
    "df2 = pd.read_csv('mari-test-balanced.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'destination': 'labels'})[['texts', 'labels']]\n",
    "df2 = df2.rename(columns={'destination': 'labels'})[['texts', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สอบถาม package internet ว่ามีแบบไหนบ้างครับ</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>พอดีพี่ซื้อเบอร์ซิม Inter ไปแล้ว แต่ยังไม่ได้ล...</td>\n",
       "      <td>billing and payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ค่ะ พี่ค่ะ คืออยู่ๆ เน็ตเล่นไม่ได้อ่ะค่ะ</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>การเปลี่ยน ระบบจาก ทรู เป็น ทรูเอช มีค่าบริการ...</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>เช็คให้หน่อยได้ไหมครับ ว่าเบอร์ของผม เปลี่ยนเป...</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts               labels\n",
       "0        สอบถาม package internet ว่ามีแบบไหนบ้างครับ           promotions\n",
       "1  พอดีพี่ซื้อเบอร์ซิม Inter ไปแล้ว แต่ยังไม่ได้ล...  billing and payment\n",
       "2           ค่ะ พี่ค่ะ คืออยู่ๆ เน็ตเล่นไม่ได้อ่ะค่ะ             internet\n",
       "3  การเปลี่ยน ระบบจาก ทรู เป็น ทรูเอช มีค่าบริการ...           promotions\n",
       "4  เช็คให้หน่อยได้ไหมครับ ว่าเบอร์ของผม เปลี่ยนเป...           promotions"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billing and payment      3916\n",
      "promotions               2280\n",
      "other queries            1823\n",
      "internet                 1588\n",
      "international dialing     336\n",
      "true money                188\n",
      "lost and stolen           172\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamin/.virtualenv/dev36/lib/python3.6/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1 2 3 4 5 6], y=[1 0 3 ... 0 0 2] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW2: {0: 0.3758572887786371, 1: 0.6455513784461153, 2: 0.8073818666248727, 3: 0.9268621806405182, 4: 4.380527210884353, 5: 7.829027355623101, 6: 8.557308970099667}\n"
     ]
    }
   ],
   "source": [
    "tmp_data = prepare_data_for_text_classification(train_dataframe=df,\n",
    "                                                test_dataframe=df2,\n",
    "                                                max_len=64,\n",
    "                                                min_len=1,\n",
    "                                                threshold_tfxidf=0.005\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the path: trained_models/text_classification\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_vectors (InputLayer)       [(None, 64, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masks (InputLayer)              [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 64, 256)      330240      word_vectors[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 64, 256)      296448      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 256)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16384)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          2097280     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32)           128         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "seq_out (Dense)                 (None, 7)            231         leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,735,431\n",
      "Trainable params: 2,734,983\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tc =Text_classification(prepared_data_dict=tmp_data, \n",
    "                        do_deep_learning=True, \n",
    "                        do_linear_classifier=True, \n",
    "                        is_sequence_prediciton=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear classifier part\n",
      "running 5-fold cv\n",
      "Best C: 5, Best f1-scores: [0.88116243 0.90909091 0.77590361 0.88172043 0.80133185 0.85617597\n",
      " 0.95238095]\n",
      "Unweighted f1-score: 0.8653951658723057, Weighted f1-score: 0.8477599212454612\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tc.fit_linear_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier part\n",
      "running 5-fold cv\n"
     ]
    }
   ],
   "source": [
    "t1 =time()\n",
    "tc.fit_SVM_classifier()\n",
    "print(f'time used: {time() - t1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "161/161 [==============================] - 43s 267ms/step - loss: 5.2349 - precision: 0.5570 - recall: 0.1550 - val_loss: 3.9366 - val_precision: 1.0000 - val_recall: 0.0027 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "161/161 [==============================] - 39s 242ms/step - loss: 2.7948 - precision: 0.7257 - recall: 0.4203 - val_loss: 2.7909 - val_precision: 0.9621 - val_recall: 0.1266 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "161/161 [==============================] - 40s 250ms/step - loss: 2.1212 - precision: 0.7195 - recall: 0.4373 - val_loss: 2.0219 - val_precision: 0.8672 - val_recall: 0.4308 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "161/161 [==============================] - 40s 246ms/step - loss: 1.7012 - precision: 0.7331 - recall: 0.4687 - val_loss: 1.7346 - val_precision: 0.7878 - val_recall: 0.4756 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "161/161 [==============================] - 38s 239ms/step - loss: 1.5439 - precision: 0.7210 - recall: 0.4641 - val_loss: 2.0209 - val_precision: 0.5560 - val_recall: 0.3636 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "161/161 [==============================] - 39s 240ms/step - loss: 1.3800 - precision: 0.7335 - recall: 0.4820 - val_loss: 1.4050 - val_precision: 0.8469 - val_recall: 0.5516 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "161/161 [==============================] - 38s 238ms/step - loss: 1.3129 - precision: 0.7373 - recall: 0.4901 - val_loss: 1.5467 - val_precision: 0.7443 - val_recall: 0.4891 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "161/161 [==============================] - 39s 239ms/step - loss: 1.3393 - precision: 0.7191 - recall: 0.4705 - val_loss: 1.4952 - val_precision: 0.7881 - val_recall: 0.5420 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "161/161 [==============================] - 39s 241ms/step - loss: 1.2401 - precision: 0.7369 - recall: 0.4948 - val_loss: 1.3586 - val_precision: 0.7714 - val_recall: 0.5190 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "161/161 [==============================] - 38s 238ms/step - loss: 1.2774 - precision: 0.7272 - recall: 0.4790 - val_loss: 1.4045 - val_precision: 0.8468 - val_recall: 0.4960 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "161/161 [==============================] - 39s 241ms/step - loss: 1.1691 - precision: 0.7382 - recall: 0.4882 - val_loss: 1.2494 - val_precision: 0.8066 - val_recall: 0.5535 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "161/161 [==============================] - 39s 244ms/step - loss: 1.1485 - precision: 0.7259 - recall: 0.4898 - val_loss: 1.4468 - val_precision: 0.7014 - val_recall: 0.4929 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "161/161 [==============================] - 38s 237ms/step - loss: 1.1703 - precision: 0.7475 - recall: 0.5087 - val_loss: 1.3589 - val_precision: 0.8199 - val_recall: 0.4768 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "161/161 [==============================] - 38s 238ms/step - loss: 1.1429 - precision: 0.7368 - recall: 0.4965 - val_loss: 1.3600 - val_precision: 0.7683 - val_recall: 0.4680 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "161/161 [==============================] - 38s 238ms/step - loss: 1.0765 - precision: 0.7449 - recall: 0.5172 - val_loss: 1.3299 - val_precision: 0.8043 - val_recall: 0.5267 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "161/161 [==============================] - 39s 239ms/step - loss: 1.0806 - precision: 0.7487 - recall: 0.5280 - val_loss: 1.2139 - val_precision: 0.8239 - val_recall: 0.5401 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "161/161 [==============================] - 40s 248ms/step - loss: 1.0351 - precision: 0.7462 - recall: 0.5206 - val_loss: 1.1503 - val_precision: 0.8143 - val_recall: 0.5819 - lr: 0.0010\n",
      "Epoch 18/500\n",
      " 47/161 [=======>......................] - ETA: 25s - loss: 1.0637 - precision: 0.7295 - recall: 0.5163"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-859222e2018f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_deep_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Thai_NLP/text_classification.py\u001b[0m in \u001b[0;36mfit_deep_learning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m           class_weight=self.class_weight)\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f1-scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dl_text_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenv/dev36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tc.fit_deep_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_prediction: [0.0339347  0.00350534 0.01975266 0.00268576 0.03924427 0.89877451\n",
      " 0.00210276]\n",
      "dl_prediction: [5.7365797e-03 9.1864483e-04 1.1742757e-02 1.7704522e-04 1.6022399e-02\n",
      " 9.6461564e-01 7.8693411e-04]\n",
      "-----\n",
      "linear_prediction: [0.59457259 0.01546059 0.22307242 0.00660594 0.11336827 0.03403696\n",
      " 0.01288323]\n",
      "dl_prediction: [0.6991231  0.00415532 0.05836102 0.00098591 0.2244429  0.01117605\n",
      " 0.00175574]\n",
      "-----\n",
      "linear_prediction: [0.0558655  0.00281539 0.90660512 0.00202166 0.01439435 0.01731933\n",
      " 0.00097867]\n",
      "dl_prediction: [1.8012861e-02 6.9103797e-04 9.5653814e-01 3.2450768e-04 1.2877582e-02\n",
      " 1.1425815e-02 1.3006906e-04]\n",
      "-----\n",
      "linear_prediction: [0.23185722 0.00862956 0.00656977 0.00102346 0.16114261 0.57616548\n",
      " 0.01461189]\n",
      "dl_prediction: [5.2739494e-02 4.3769574e-04 1.4137422e-02 4.6365586e-04 8.4993333e-01\n",
      " 7.8846194e-02 3.4423808e-03]\n",
      "-----\n",
      "linear_prediction: [0.21933552 0.00306056 0.07012364 0.00992462 0.05556976 0.62816136\n",
      " 0.01382454]\n",
      "dl_prediction: [3.0957642e-01 7.2698586e-04 2.4192347e-03 4.9792684e-04 4.9165066e-02\n",
      " 6.3102263e-01 6.5917149e-03]\n",
      "-----\n",
      "linear_prediction: [2.56189122e-02 1.29249561e-02 1.62641454e-02 9.13701156e-01\n",
      " 1.90618527e-02 1.19143857e-02 5.14592389e-04]\n",
      "dl_prediction: [7.8318879e-04 7.6709301e-05 1.5792907e-04 9.9708897e-01 1.8098095e-03\n",
      " 4.8922047e-05 3.4527216e-05]\n",
      "-----\n",
      "linear_prediction: [0.10404294 0.06425434 0.61854761 0.01023475 0.1422615  0.05595999\n",
      " 0.00469888]\n",
      "dl_prediction: [1.1112118e-01 2.9082848e-03 4.6454719e-01 2.7517208e-03 3.9096025e-01\n",
      " 2.7420441e-02 2.9091680e-04]\n",
      "-----\n",
      "linear_prediction: [1.97358712e-02 4.07974628e-03 8.73629035e-01 7.02493475e-04\n",
      " 2.35108212e-02 7.45455272e-02 3.79650528e-03]\n",
      "dl_prediction: [4.2843521e-02 3.4353118e-03 8.4113276e-01 5.0463149e-04 7.7698790e-02\n",
      " 3.3946056e-02 4.3886460e-04]\n",
      "-----\n",
      "linear_prediction: [0.14273474 0.00802081 0.22616726 0.00392733 0.09614812 0.51974854\n",
      " 0.0032532 ]\n",
      "dl_prediction: [1.4823186e-01 2.4466962e-03 1.0949808e-02 5.8267376e-04 3.7034001e-02\n",
      " 7.9826432e-01 2.4906085e-03]\n",
      "-----\n",
      "linear_prediction: [0.98144437 0.0033973  0.00170466 0.00126824 0.00657577 0.0046169\n",
      " 0.00099277]\n",
      "dl_prediction: [9.9425703e-01 7.0966972e-04 2.4589419e-04 7.7460171e-04 1.7728299e-03\n",
      " 1.2692290e-03 9.7077264e-04]\n",
      "-----\n",
      "linear_prediction: [7.96273943e-03 2.85940908e-02 1.07610540e-01 2.23046524e-03\n",
      " 3.98174141e-03 8.49073438e-01 5.46985147e-04]\n",
      "dl_prediction: [2.5079131e-02 8.5703610e-03 1.1873365e-02 1.8065145e-04 9.0701524e-03\n",
      " 9.4493026e-01 2.9597140e-04]\n",
      "-----\n",
      "linear_prediction: [0.45549046 0.00822083 0.36571715 0.00289666 0.02324792 0.13416576\n",
      " 0.01026122]\n",
      "dl_prediction: [0.4177141  0.00087204 0.24851364 0.00146091 0.30718037 0.02258547\n",
      " 0.00167352]\n",
      "-----\n",
      "linear_prediction: [0.04384729 0.00789049 0.60372259 0.0026439  0.24422968 0.09433458\n",
      " 0.00333148]\n",
      "dl_prediction: [8.5508004e-03 4.3059379e-04 8.9517921e-01 3.1836313e-04 6.9437511e-02\n",
      " 2.5327224e-02 7.5619138e-04]\n",
      "-----\n",
      "linear_prediction: [0.21071743 0.0096965  0.25857259 0.00753121 0.3438839  0.14189492\n",
      " 0.02770345]\n",
      "dl_prediction: [0.4242746  0.00337598 0.4727537  0.00144612 0.08623768 0.01038723\n",
      " 0.0015247 ]\n",
      "-----\n",
      "linear_prediction: [0.02543676 0.00216771 0.0035267  0.00153248 0.04556641 0.9207572\n",
      " 0.00101273]\n",
      "dl_prediction: [5.1819224e-02 6.6838285e-04 9.3583623e-03 1.8350106e-04 4.1993383e-02\n",
      " 8.9489728e-01 1.0799189e-03]\n",
      "-----\n",
      "linear_prediction: [6.37210745e-03 2.81332295e-03 1.56026981e-02 6.99463049e-04\n",
      " 1.01160154e-02 9.63896737e-01 4.99656439e-04]\n",
      "dl_prediction: [1.4219227e-02 1.7559717e-03 4.3305207e-02 8.4616325e-04 5.2411135e-02\n",
      " 8.8686669e-01 5.9561938e-04]\n",
      "-----\n",
      "linear_prediction: [0.04698074 0.00301938 0.00274227 0.00124528 0.07900774 0.86168369\n",
      " 0.0053209 ]\n",
      "dl_prediction: [0.3070049  0.00168111 0.00611421 0.00098716 0.03954341 0.6075125\n",
      " 0.03715672]\n",
      "-----\n",
      "linear_prediction: [0.03013303 0.00393642 0.74181763 0.00285071 0.01530603 0.20335456\n",
      " 0.00260163]\n",
      "dl_prediction: [1.2561694e-01 5.4099415e-03 7.3222589e-01 8.9730439e-04 7.3199861e-02\n",
      " 6.2105309e-02 5.4476730e-04]\n",
      "-----\n",
      "linear_prediction: [0.0144758  0.00597145 0.81125814 0.00091053 0.1595945  0.00299794\n",
      " 0.00479163]\n",
      "dl_prediction: [2.4901240e-03 2.0967446e-04 9.3372804e-01 9.3576533e-04 5.9314106e-02\n",
      " 3.0165939e-03 3.0568495e-04]\n",
      "-----\n",
      "linear_prediction: [0.68472702 0.00372624 0.15376031 0.00152274 0.07913434 0.02077305\n",
      " 0.0563563 ]\n",
      "dl_prediction: [0.42470765 0.00153522 0.01426595 0.00223997 0.17765713 0.01673974\n",
      " 0.3628543 ]\n",
      "-----\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 21)           168         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 21)           168         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 21)           84          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 21)           84          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 21)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 21)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 21)           0           leaky_re_lu[0][0]                \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 21)           0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14)           308         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14)           56          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 14)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14)           0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            105         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 973\n",
      "Trainable params: 861\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n",
      "(10303, 7)\n",
      "(10303, 7)\n",
      "(10303, 7)\n",
      "(2607, 7)\n",
      "(2607, 7)\n",
      "(2607, 7)\n",
      "{0: 0.3758572887786371, 1: 4.380527210884353, 2: 0.9268621806405182, 3: 8.557308970099667, 4: 0.8073818666248727, 5: 0.6455513784461153, 6: 7.829027355623101}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 75ms/step - loss: 2.2747 - precision: 0.0704 - recall: 0.0037 - val_loss: 2.1464 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.8477 - precision: 0.5604 - recall: 0.0239 - val_loss: 2.0835 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.5258 - precision: 0.8487 - recall: 0.0741 - val_loss: 2.0269 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 1.2860 - precision: 0.8939 - recall: 0.1382 - val_loss: 1.9780 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 1.1147 - precision: 0.9111 - recall: 0.2049 - val_loss: 1.9382 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.9702 - precision: 0.9238 - recall: 0.2882 - val_loss: 1.8970 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.8755 - precision: 0.9441 - recall: 0.4064 - val_loss: 1.8584 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.8109 - precision: 0.9441 - recall: 0.4968 - val_loss: 1.8190 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.7668 - precision: 0.9464 - recall: 0.5609 - val_loss: 1.7806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.7177 - precision: 0.9488 - recall: 0.6150 - val_loss: 1.7427 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.6894 - precision: 0.9469 - recall: 0.6473 - val_loss: 1.7068 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6551 - precision: 0.9495 - recall: 0.6842 - val_loss: 1.6721 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.6349 - precision: 0.9479 - recall: 0.7043 - val_loss: 1.6365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.6175 - precision: 0.9488 - recall: 0.7273 - val_loss: 1.6002 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.5894 - precision: 0.9473 - recall: 0.7490 - val_loss: 1.5612 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.5780 - precision: 0.9520 - recall: 0.7635 - val_loss: 1.5234 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.5695 - precision: 0.9491 - recall: 0.7805 - val_loss: 1.4888 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.5548 - precision: 0.9487 - recall: 0.7865 - val_loss: 1.4513 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.5305 - precision: 0.9504 - recall: 0.8000 - val_loss: 1.4132 - val_precision: 1.0000 - val_recall: 0.0690 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.5247 - precision: 0.9497 - recall: 0.8108 - val_loss: 1.3749 - val_precision: 1.0000 - val_recall: 0.1343 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5176 - precision: 0.9521 - recall: 0.8183 - val_loss: 1.3404 - val_precision: 0.9920 - val_recall: 0.1899 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.5056 - precision: 0.9484 - recall: 0.8257 - val_loss: 1.3053 - val_precision: 0.9771 - val_recall: 0.2455 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.4938 - precision: 0.9474 - recall: 0.8313 - val_loss: 1.2736 - val_precision: 0.9720 - val_recall: 0.2800 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.4863 - precision: 0.9496 - recall: 0.8351 - val_loss: 1.2404 - val_precision: 0.9684 - val_recall: 0.3525 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.4799 - precision: 0.9476 - recall: 0.8412 - val_loss: 1.2121 - val_precision: 0.9597 - val_recall: 0.4200 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4652 - precision: 0.9486 - recall: 0.8476 - val_loss: 1.1832 - val_precision: 0.9481 - val_recall: 0.4691 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.4609 - precision: 0.9476 - recall: 0.8488 - val_loss: 1.1556 - val_precision: 0.9392 - val_recall: 0.5094 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.4544 - precision: 0.9481 - recall: 0.8522 - val_loss: 1.1277 - val_precision: 0.9359 - val_recall: 0.5432 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.4507 - precision: 0.9476 - recall: 0.8584 - val_loss: 1.1014 - val_precision: 0.9327 - val_recall: 0.5689 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.4427 - precision: 0.9479 - recall: 0.8618 - val_loss: 1.0819 - val_precision: 0.9286 - val_recall: 0.5884 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4342 - precision: 0.9474 - recall: 0.8668 - val_loss: 1.0618 - val_precision: 0.9269 - val_recall: 0.6030 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4319 - precision: 0.9491 - recall: 0.8664 - val_loss: 1.0417 - val_precision: 0.9213 - val_recall: 0.6195 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.4212 - precision: 0.9467 - recall: 0.8736 - val_loss: 1.0252 - val_precision: 0.9182 - val_recall: 0.6283 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.4168 - precision: 0.9497 - recall: 0.8756 - val_loss: 1.0102 - val_precision: 0.9154 - val_recall: 0.6390 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.4139 - precision: 0.9484 - recall: 0.8796 - val_loss: 0.9952 - val_precision: 0.9123 - val_recall: 0.6548 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.4078 - precision: 0.9496 - recall: 0.8801 - val_loss: 0.9838 - val_precision: 0.9071 - val_recall: 0.6632 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.4022 - precision: 0.9483 - recall: 0.8842 - val_loss: 0.9717 - val_precision: 0.9035 - val_recall: 0.6717 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3961 - precision: 0.9492 - recall: 0.8859 - val_loss: 0.9646 - val_precision: 0.8981 - val_recall: 0.6759 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3933 - precision: 0.9464 - recall: 0.8865 - val_loss: 0.9590 - val_precision: 0.8953 - val_recall: 0.6793 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3926 - precision: 0.9493 - recall: 0.8861 - val_loss: 0.9487 - val_precision: 0.8900 - val_recall: 0.6858 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3852 - precision: 0.9490 - recall: 0.8907 - val_loss: 0.9411 - val_precision: 0.8855 - val_recall: 0.6885 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3852 - precision: 0.9476 - recall: 0.8939 - val_loss: 0.9373 - val_precision: 0.8830 - val_recall: 0.6916 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3750 - precision: 0.9474 - recall: 0.8940 - val_loss: 0.9349 - val_precision: 0.8766 - val_recall: 0.6920 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3751 - precision: 0.9482 - recall: 0.8955 - val_loss: 0.9318 - val_precision: 0.8739 - val_recall: 0.6935 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3691 - precision: 0.9485 - recall: 0.8966 - val_loss: 0.9273 - val_precision: 0.8694 - val_recall: 0.6943 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3629 - precision: 0.9492 - recall: 0.8990 - val_loss: 0.9240 - val_precision: 0.8642 - val_recall: 0.6931 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.3613 - precision: 0.9486 - recall: 0.8990 - val_loss: 0.9249 - val_precision: 0.8572 - val_recall: 0.6885 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3590 - precision: 0.9471 - recall: 0.8996 - val_loss: 0.9221 - val_precision: 0.8530 - val_recall: 0.6920 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3534 - precision: 0.9481 - recall: 0.9019 - val_loss: 0.9178 - val_precision: 0.8474 - val_recall: 0.6924 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3561 - precision: 0.9471 - recall: 0.9011 - val_loss: 0.9141 - val_precision: 0.8448 - val_recall: 0.6951 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3498 - precision: 0.9493 - recall: 0.9031 - val_loss: 0.9095 - val_precision: 0.8457 - val_recall: 0.7020 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3475 - precision: 0.9488 - recall: 0.9048 - val_loss: 0.9089 - val_precision: 0.8421 - val_recall: 0.7035 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3443 - precision: 0.9495 - recall: 0.9062 - val_loss: 0.9089 - val_precision: 0.8390 - val_recall: 0.7039 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3440 - precision: 0.9474 - recall: 0.9045 - val_loss: 0.9105 - val_precision: 0.8286 - val_recall: 0.6974 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3423 - precision: 0.9476 - recall: 0.9043 - val_loss: 0.9102 - val_precision: 0.8225 - val_recall: 0.6931 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3353 - precision: 0.9488 - recall: 0.9087 - val_loss: 0.9060 - val_precision: 0.8240 - val_recall: 0.6985 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.3341 - precision: 0.9479 - recall: 0.9078 - val_loss: 0.9023 - val_precision: 0.8252 - val_recall: 0.7008 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3308 - precision: 0.9484 - recall: 0.9099 - val_loss: 0.9019 - val_precision: 0.8197 - val_recall: 0.6977 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3228 - precision: 0.9503 - recall: 0.9116 - val_loss: 0.8952 - val_precision: 0.8256 - val_recall: 0.7066 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3266 - precision: 0.9486 - recall: 0.9065 - val_loss: 0.8922 - val_precision: 0.8245 - val_recall: 0.7062 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3209 - precision: 0.9489 - recall: 0.9111 - val_loss: 0.8870 - val_precision: 0.8244 - val_recall: 0.7096 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3179 - precision: 0.9508 - recall: 0.9107 - val_loss: 0.8863 - val_precision: 0.8193 - val_recall: 0.7062 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3152 - precision: 0.9481 - recall: 0.9111 - val_loss: 0.8841 - val_precision: 0.8166 - val_recall: 0.7035 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.3149 - precision: 0.9500 - recall: 0.9107 - val_loss: 0.8860 - val_precision: 0.8115 - val_recall: 0.6985 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3127 - precision: 0.9503 - recall: 0.9116 - val_loss: 0.8807 - val_precision: 0.8207 - val_recall: 0.7077 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.3087 - precision: 0.9479 - recall: 0.9102 - val_loss: 0.8735 - val_precision: 0.8264 - val_recall: 0.7158 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3064 - precision: 0.9491 - recall: 0.9129 - val_loss: 0.8696 - val_precision: 0.8275 - val_recall: 0.7177 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3059 - precision: 0.9471 - recall: 0.9130 - val_loss: 0.8697 - val_precision: 0.8238 - val_recall: 0.7158 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3030 - precision: 0.9484 - recall: 0.9138 - val_loss: 0.8616 - val_precision: 0.8311 - val_recall: 0.7211 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3013 - precision: 0.9483 - recall: 0.9129 - val_loss: 0.8580 - val_precision: 0.8320 - val_recall: 0.7257 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3014 - precision: 0.9477 - recall: 0.9126 - val_loss: 0.8524 - val_precision: 0.8374 - val_recall: 0.7307 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3005 - precision: 0.9466 - recall: 0.9138 - val_loss: 0.8435 - val_precision: 0.8398 - val_recall: 0.7361 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2937 - precision: 0.9474 - recall: 0.9142 - val_loss: 0.8364 - val_precision: 0.8430 - val_recall: 0.7395 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2988 - precision: 0.9474 - recall: 0.9128 - val_loss: 0.8328 - val_precision: 0.8447 - val_recall: 0.7407 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2954 - precision: 0.9478 - recall: 0.9180 - val_loss: 0.8368 - val_precision: 0.8406 - val_recall: 0.7346 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2918 - precision: 0.9464 - recall: 0.9155 - val_loss: 0.8356 - val_precision: 0.8393 - val_recall: 0.7334 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2873 - precision: 0.9483 - recall: 0.9159 - val_loss: 0.8304 - val_precision: 0.8398 - val_recall: 0.7380 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2853 - precision: 0.9457 - recall: 0.9164 - val_loss: 0.8229 - val_precision: 0.8448 - val_recall: 0.7415 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2876 - precision: 0.9465 - recall: 0.9160 - val_loss: 0.8155 - val_precision: 0.8480 - val_recall: 0.7445 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2801 - precision: 0.9472 - recall: 0.9158 - val_loss: 0.8108 - val_precision: 0.8510 - val_recall: 0.7472 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2843 - precision: 0.9468 - recall: 0.9182 - val_loss: 0.8121 - val_precision: 0.8484 - val_recall: 0.7430 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2823 - precision: 0.9483 - recall: 0.9172 - val_loss: 0.8079 - val_precision: 0.8490 - val_recall: 0.7442 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.2803 - precision: 0.9472 - recall: 0.9165 - val_loss: 0.8001 - val_precision: 0.8527 - val_recall: 0.7484 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2768 - precision: 0.9469 - recall: 0.9188 - val_loss: 0.7979 - val_precision: 0.8535 - val_recall: 0.7488 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2796 - precision: 0.9472 - recall: 0.9190 - val_loss: 0.7988 - val_precision: 0.8535 - val_recall: 0.7488 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2757 - precision: 0.9499 - recall: 0.9193 - val_loss: 0.7910 - val_precision: 0.8521 - val_recall: 0.7491 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2718 - precision: 0.9463 - recall: 0.9164 - val_loss: 0.7828 - val_precision: 0.8549 - val_recall: 0.7526 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2717 - precision: 0.9469 - recall: 0.9163 - val_loss: 0.7713 - val_precision: 0.8576 - val_recall: 0.7599 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2716 - precision: 0.9485 - recall: 0.9183 - val_loss: 0.7630 - val_precision: 0.8581 - val_recall: 0.7629 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2682 - precision: 0.9479 - recall: 0.9182 - val_loss: 0.7570 - val_precision: 0.8582 - val_recall: 0.7660 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.2653 - precision: 0.9479 - recall: 0.9176 - val_loss: 0.7489 - val_precision: 0.8618 - val_recall: 0.7702 - lr: 0.0010\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2653 - precision: 0.9472 - recall: 0.9173 - val_loss: 0.7443 - val_precision: 0.8611 - val_recall: 0.7752 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2620 - precision: 0.9473 - recall: 0.9166 - val_loss: 0.7386 - val_precision: 0.8628 - val_recall: 0.7768 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2641 - precision: 0.9469 - recall: 0.9164 - val_loss: 0.7345 - val_precision: 0.8626 - val_recall: 0.7802 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2617 - precision: 0.9451 - recall: 0.9171 - val_loss: 0.7301 - val_precision: 0.8631 - val_recall: 0.7833 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2594 - precision: 0.9489 - recall: 0.9227 - val_loss: 0.7231 - val_precision: 0.8624 - val_recall: 0.7860 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2582 - precision: 0.9484 - recall: 0.9207 - val_loss: 0.7320 - val_precision: 0.8609 - val_recall: 0.7810 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2562 - precision: 0.9474 - recall: 0.9194 - val_loss: 0.7270 - val_precision: 0.8619 - val_recall: 0.7806 - lr: 0.0010\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2535 - precision: 0.9469 - recall: 0.9204 - val_loss: 0.7215 - val_precision: 0.8618 - val_recall: 0.7844 - lr: 0.0010\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2531 - precision: 0.9486 - recall: 0.9198 - val_loss: 0.7186 - val_precision: 0.8625 - val_recall: 0.7871 - lr: 0.0010\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2551 - precision: 0.9482 - recall: 0.9223 - val_loss: 0.7132 - val_precision: 0.8635 - val_recall: 0.7886 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2513 - precision: 0.9496 - recall: 0.9237 - val_loss: 0.7085 - val_precision: 0.8637 - val_recall: 0.7902 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2520 - precision: 0.9468 - recall: 0.9206 - val_loss: 0.7032 - val_precision: 0.8620 - val_recall: 0.7906 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2463 - precision: 0.9466 - recall: 0.9213 - val_loss: 0.6970 - val_precision: 0.8630 - val_recall: 0.7929 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2483 - precision: 0.9460 - recall: 0.9220 - val_loss: 0.6941 - val_precision: 0.8633 - val_recall: 0.7971 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2483 - precision: 0.9462 - recall: 0.9212 - val_loss: 0.6874 - val_precision: 0.8669 - val_recall: 0.8017 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2466 - precision: 0.9481 - recall: 0.9220 - val_loss: 0.6874 - val_precision: 0.8658 - val_recall: 0.7994 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2512 - precision: 0.9447 - recall: 0.9200 - val_loss: 0.6868 - val_precision: 0.8658 - val_recall: 0.7971 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2456 - precision: 0.9465 - recall: 0.9220 - val_loss: 0.6873 - val_precision: 0.8657 - val_recall: 0.7963 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.2403 - precision: 0.9478 - recall: 0.9231 - val_loss: 0.6840 - val_precision: 0.8657 - val_recall: 0.7963 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2427 - precision: 0.9484 - recall: 0.9221 - val_loss: 0.6786 - val_precision: 0.8659 - val_recall: 0.7979 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2404 - precision: 0.9476 - recall: 0.9216 - val_loss: 0.6777 - val_precision: 0.8672 - val_recall: 0.7994 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2390 - precision: 0.9475 - recall: 0.9213 - val_loss: 0.6770 - val_precision: 0.8656 - val_recall: 0.8002 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2381 - precision: 0.9483 - recall: 0.9256 - val_loss: 0.6705 - val_precision: 0.8649 - val_recall: 0.8028 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2365 - precision: 0.9476 - recall: 0.9202 - val_loss: 0.6657 - val_precision: 0.8673 - val_recall: 0.8048 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2384 - precision: 0.9485 - recall: 0.9211 - val_loss: 0.6639 - val_precision: 0.8680 - val_recall: 0.8044 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2332 - precision: 0.9492 - recall: 0.9238 - val_loss: 0.6631 - val_precision: 0.8682 - val_recall: 0.8036 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2376 - precision: 0.9476 - recall: 0.9215 - val_loss: 0.6612 - val_precision: 0.8682 - val_recall: 0.8032 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2349 - precision: 0.9467 - recall: 0.9218 - val_loss: 0.6583 - val_precision: 0.8672 - val_recall: 0.8063 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2340 - precision: 0.9460 - recall: 0.9222 - val_loss: 0.6600 - val_precision: 0.8680 - val_recall: 0.8074 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2347 - precision: 0.9479 - recall: 0.9238 - val_loss: 0.6585 - val_precision: 0.8661 - val_recall: 0.8067 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2323 - precision: 0.9462 - recall: 0.9238 - val_loss: 0.6574 - val_precision: 0.8643 - val_recall: 0.8059 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2331 - precision: 0.9468 - recall: 0.9216 - val_loss: 0.6549 - val_precision: 0.8639 - val_recall: 0.8059 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2293 - precision: 0.9474 - recall: 0.9222 - val_loss: 0.6487 - val_precision: 0.8647 - val_recall: 0.8067 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.2303 - precision: 0.9487 - recall: 0.9228 - val_loss: 0.6466 - val_precision: 0.8647 - val_recall: 0.8063 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2284 - precision: 0.9467 - recall: 0.9224 - val_loss: 0.6473 - val_precision: 0.8643 - val_recall: 0.8063 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2279 - precision: 0.9460 - recall: 0.9232 - val_loss: 0.6575 - val_precision: 0.8606 - val_recall: 0.7982 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2284 - precision: 0.9475 - recall: 0.9225 - val_loss: 0.6511 - val_precision: 0.8622 - val_recall: 0.7994 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2273 - precision: 0.9483 - recall: 0.9226 - val_loss: 0.6477 - val_precision: 0.8646 - val_recall: 0.8036 - lr: 0.0010\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2259 - precision: 0.9482 - recall: 0.9237 - val_loss: 0.6457 - val_precision: 0.8639 - val_recall: 0.8059 - lr: 0.0010\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2241 - precision: 0.9468 - recall: 0.9232 - val_loss: 0.6416 - val_precision: 0.8643 - val_recall: 0.8063 - lr: 0.0010\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2237 - precision: 0.9475 - recall: 0.9248 - val_loss: 0.6371 - val_precision: 0.8640 - val_recall: 0.8090 - lr: 0.0010\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2213 - precision: 0.9477 - recall: 0.9228 - val_loss: 0.6364 - val_precision: 0.8643 - val_recall: 0.8109 - lr: 0.0010\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.2203 - precision: 0.9476 - recall: 0.9251 - val_loss: 0.6343 - val_precision: 0.8640 - val_recall: 0.8094 - lr: 0.0010\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2165 - precision: 0.9477 - recall: 0.9271 - val_loss: 0.6309 - val_precision: 0.8650 - val_recall: 0.8113 - lr: 0.0010\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2212 - precision: 0.9462 - recall: 0.9247 - val_loss: 0.6331 - val_precision: 0.8627 - val_recall: 0.8097 - lr: 0.0010\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.2213 - precision: 0.9470 - recall: 0.9248 - val_loss: 0.6305 - val_precision: 0.8636 - val_recall: 0.8109 - lr: 0.0010\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2174 - precision: 0.9485 - recall: 0.9265 - val_loss: 0.6280 - val_precision: 0.8627 - val_recall: 0.8120 - lr: 0.0010\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2161 - precision: 0.9480 - recall: 0.9279 - val_loss: 0.6334 - val_precision: 0.8605 - val_recall: 0.8090 - lr: 0.0010\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2202 - precision: 0.9477 - recall: 0.9270 - val_loss: 0.6338 - val_precision: 0.8595 - val_recall: 0.8097 - lr: 0.0010\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2169 - precision: 0.9456 - recall: 0.9237 - val_loss: 0.6307 - val_precision: 0.8617 - val_recall: 0.8101 - lr: 0.0010\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2175 - precision: 0.9474 - recall: 0.9263 - val_loss: 0.6259 - val_precision: 0.8615 - val_recall: 0.8113 - lr: 0.0010\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2146 - precision: 0.9463 - recall: 0.9240 - val_loss: 0.6260 - val_precision: 0.8588 - val_recall: 0.8117 - lr: 0.0010\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2143 - precision: 0.9470 - recall: 0.9255 - val_loss: 0.6256 - val_precision: 0.8596 - val_recall: 0.8101 - lr: 0.0010\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2161 - precision: 0.9472 - recall: 0.9253 - val_loss: 0.6258 - val_precision: 0.8591 - val_recall: 0.8113 - lr: 0.0010\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2107 - precision: 0.9497 - recall: 0.9283 - val_loss: 0.6241 - val_precision: 0.8606 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2112 - precision: 0.9481 - recall: 0.9264 - val_loss: 0.6232 - val_precision: 0.8603 - val_recall: 0.8105 - lr: 0.0010\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2133 - precision: 0.9465 - recall: 0.9252 - val_loss: 0.6228 - val_precision: 0.8595 - val_recall: 0.8117 - lr: 0.0010\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2111 - precision: 0.9464 - recall: 0.9257 - val_loss: 0.6229 - val_precision: 0.8600 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2111 - precision: 0.9498 - recall: 0.9241 - val_loss: 0.6224 - val_precision: 0.8589 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2092 - precision: 0.9472 - recall: 0.9250 - val_loss: 0.6185 - val_precision: 0.8600 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2104 - precision: 0.9460 - recall: 0.9240 - val_loss: 0.6178 - val_precision: 0.8635 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2111 - precision: 0.9473 - recall: 0.9267 - val_loss: 0.6198 - val_precision: 0.8610 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2092 - precision: 0.9468 - recall: 0.9253 - val_loss: 0.6188 - val_precision: 0.8599 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2067 - precision: 0.9452 - recall: 0.9257 - val_loss: 0.6161 - val_precision: 0.8610 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2075 - precision: 0.9469 - recall: 0.9285 - val_loss: 0.6330 - val_precision: 0.8573 - val_recall: 0.8040 - lr: 0.0010\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2098 - precision: 0.9455 - recall: 0.9233 - val_loss: 0.6270 - val_precision: 0.8591 - val_recall: 0.8090 - lr: 0.0010\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2047 - precision: 0.9462 - recall: 0.9252 - val_loss: 0.6204 - val_precision: 0.8600 - val_recall: 0.8105 - lr: 0.0010\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2057 - precision: 0.9471 - recall: 0.9266 - val_loss: 0.6219 - val_precision: 0.8585 - val_recall: 0.8097 - lr: 0.0010\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2081 - precision: 0.9471 - recall: 0.9235 - val_loss: 0.6195 - val_precision: 0.8580 - val_recall: 0.8136 - lr: 0.0010\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2050 - precision: 0.9483 - recall: 0.9273 - val_loss: 0.6157 - val_precision: 0.8588 - val_recall: 0.8143 - lr: 0.0010\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2041 - precision: 0.9480 - recall: 0.9277 - val_loss: 0.6188 - val_precision: 0.8571 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2003 - precision: 0.9496 - recall: 0.9313 - val_loss: 0.6158 - val_precision: 0.8566 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2033 - precision: 0.9491 - recall: 0.9289 - val_loss: 0.6141 - val_precision: 0.8564 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2043 - precision: 0.9479 - recall: 0.9280 - val_loss: 0.6132 - val_precision: 0.8560 - val_recall: 0.8120 - lr: 0.0010\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2002 - precision: 0.9473 - recall: 0.9253 - val_loss: 0.6125 - val_precision: 0.8566 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2011 - precision: 0.9479 - recall: 0.9267 - val_loss: 0.6134 - val_precision: 0.8554 - val_recall: 0.8120 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2003 - precision: 0.9482 - recall: 0.9290 - val_loss: 0.6130 - val_precision: 0.8569 - val_recall: 0.8105 - lr: 0.0010\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.1984 - precision: 0.9462 - recall: 0.9264 - val_loss: 0.6080 - val_precision: 0.8571 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2005 - precision: 0.9474 - recall: 0.9269 - val_loss: 0.6132 - val_precision: 0.8557 - val_recall: 0.8120 - lr: 0.0010\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2003 - precision: 0.9478 - recall: 0.9285 - val_loss: 0.6155 - val_precision: 0.8562 - val_recall: 0.8109 - lr: 0.0010\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1985 - precision: 0.9480 - recall: 0.9292 - val_loss: 0.6105 - val_precision: 0.8591 - val_recall: 0.8140 - lr: 0.0010\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1999 - precision: 0.9483 - recall: 0.9285 - val_loss: 0.6059 - val_precision: 0.8596 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2003 - precision: 0.9466 - recall: 0.9271 - val_loss: 0.6069 - val_precision: 0.8573 - val_recall: 0.8136 - lr: 0.0010\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2005 - precision: 0.9470 - recall: 0.9247 - val_loss: 0.6079 - val_precision: 0.8569 - val_recall: 0.8105 - lr: 0.0010\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.1954 - precision: 0.9473 - recall: 0.9288 - val_loss: 0.6047 - val_precision: 0.8559 - val_recall: 0.8113 - lr: 0.0010\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1968 - precision: 0.9480 - recall: 0.9261 - val_loss: 0.6074 - val_precision: 0.8551 - val_recall: 0.8101 - lr: 0.0010\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1964 - precision: 0.9486 - recall: 0.9274 - val_loss: 0.6057 - val_precision: 0.8569 - val_recall: 0.8109 - lr: 0.0010\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1972 - precision: 0.9482 - recall: 0.9289 - val_loss: 0.6066 - val_precision: 0.8560 - val_recall: 0.8097 - lr: 0.0010\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1975 - precision: 0.9468 - recall: 0.9261 - val_loss: 0.6039 - val_precision: 0.8566 - val_recall: 0.8136 - lr: 0.0010\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1989 - precision: 0.9476 - recall: 0.9276 - val_loss: 0.6031 - val_precision: 0.8565 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1973 - precision: 0.9489 - recall: 0.9293 - val_loss: 0.6034 - val_precision: 0.8555 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1931 - precision: 0.9463 - recall: 0.9256 - val_loss: 0.6040 - val_precision: 0.8563 - val_recall: 0.8117 - lr: 0.0010\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1937 - precision: 0.9476 - recall: 0.9275 - val_loss: 0.6007 - val_precision: 0.8568 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1915 - precision: 0.9502 - recall: 0.9310 - val_loss: 0.6053 - val_precision: 0.8558 - val_recall: 0.8082 - lr: 0.0010\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1929 - precision: 0.9489 - recall: 0.9280 - val_loss: 0.6058 - val_precision: 0.8561 - val_recall: 0.8078 - lr: 0.0010\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1903 - precision: 0.9474 - recall: 0.9284 - val_loss: 0.6038 - val_precision: 0.8554 - val_recall: 0.8120 - lr: 0.0010\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1946 - precision: 0.9468 - recall: 0.9275 - val_loss: 0.5998 - val_precision: 0.8563 - val_recall: 0.8140 - lr: 0.0010\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1925 - precision: 0.9465 - recall: 0.9280 - val_loss: 0.5998 - val_precision: 0.8560 - val_recall: 0.8143 - lr: 0.0010\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1897 - precision: 0.9481 - recall: 0.9285 - val_loss: 0.6053 - val_precision: 0.8543 - val_recall: 0.8120 - lr: 0.0010\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.1932 - precision: 0.9477 - recall: 0.9301 - val_loss: 0.5986 - val_precision: 0.8555 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1940 - precision: 0.9467 - recall: 0.9266 - val_loss: 0.5932 - val_precision: 0.8559 - val_recall: 0.8109 - lr: 0.0010\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1961 - precision: 0.9456 - recall: 0.9238 - val_loss: 0.5942 - val_precision: 0.8566 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1901 - precision: 0.9461 - recall: 0.9262 - val_loss: 0.5987 - val_precision: 0.8555 - val_recall: 0.8128 - lr: 0.0010\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1892 - precision: 0.9474 - recall: 0.9271 - val_loss: 0.6047 - val_precision: 0.8536 - val_recall: 0.8120 - lr: 0.0010\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1899 - precision: 0.9467 - recall: 0.9271 - val_loss: 0.6040 - val_precision: 0.8551 - val_recall: 0.8101 - lr: 0.0010\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1890 - precision: 0.9474 - recall: 0.9293 - val_loss: 0.6002 - val_precision: 0.8535 - val_recall: 0.8155 - lr: 0.0010\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1908 - precision: 0.9462 - recall: 0.9287 - val_loss: 0.5992 - val_precision: 0.8561 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1888 - precision: 0.9484 - recall: 0.9296 - val_loss: 0.6041 - val_precision: 0.8536 - val_recall: 0.8143 - lr: 0.0010\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1872 - precision: 0.9473 - recall: 0.9292 - val_loss: 0.6054 - val_precision: 0.8547 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1908 - precision: 0.9497 - recall: 0.9292 - val_loss: 0.6056 - val_precision: 0.8544 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1883 - precision: 0.9462 - recall: 0.9278 - val_loss: 0.6092 - val_precision: 0.8541 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1864 - precision: 0.9462 - recall: 0.9270 - val_loss: 0.6058 - val_precision: 0.8521 - val_recall: 0.8136 - lr: 0.0010\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1900 - precision: 0.9463 - recall: 0.9259 - val_loss: 0.6001 - val_precision: 0.8522 - val_recall: 0.8140 - lr: 0.0010\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1889 - precision: 0.9458 - recall: 0.9256 - val_loss: 0.5974 - val_precision: 0.8551 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1877 - precision: 0.9459 - recall: 0.9290 - val_loss: 0.5975 - val_precision: 0.8548 - val_recall: 0.8151 - lr: 0.0010\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1863 - precision: 0.9489 - recall: 0.9290 - val_loss: 0.5957 - val_precision: 0.8530 - val_recall: 0.8166 - lr: 0.0010\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1853 - precision: 0.9468 - recall: 0.9282 - val_loss: 0.5986 - val_precision: 0.8522 - val_recall: 0.8140 - lr: 0.0010\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1878 - precision: 0.9483 - recall: 0.9285 - val_loss: 0.5977 - val_precision: 0.8541 - val_recall: 0.8174 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1865 - precision: 0.9463 - recall: 0.9257 - val_loss: 0.5902 - val_precision: 0.8557 - val_recall: 0.8166 - lr: 0.0010\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1857 - precision: 0.9455 - recall: 0.9256 - val_loss: 0.5932 - val_precision: 0.8555 - val_recall: 0.8155 - lr: 0.0010\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1855 - precision: 0.9470 - recall: 0.9292 - val_loss: 0.5968 - val_precision: 0.8537 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1864 - precision: 0.9474 - recall: 0.9295 - val_loss: 0.6029 - val_precision: 0.8551 - val_recall: 0.8151 - lr: 0.0010\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1852 - precision: 0.9445 - recall: 0.9282 - val_loss: 0.6013 - val_precision: 0.8542 - val_recall: 0.8155 - lr: 0.0010\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1852 - precision: 0.9459 - recall: 0.9239 - val_loss: 0.5977 - val_precision: 0.8544 - val_recall: 0.8170 - lr: 0.0010\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1826 - precision: 0.9467 - recall: 0.9298 - val_loss: 0.5974 - val_precision: 0.8530 - val_recall: 0.8189 - lr: 0.0010\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1839 - precision: 0.9473 - recall: 0.9293 - val_loss: 0.5996 - val_precision: 0.8544 - val_recall: 0.8170 - lr: 0.0010\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1838 - precision: 0.9472 - recall: 0.9269 - val_loss: 0.5978 - val_precision: 0.8542 - val_recall: 0.8201 - lr: 0.0010\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1829 - precision: 0.9460 - recall: 0.9272 - val_loss: 0.5947 - val_precision: 0.8535 - val_recall: 0.8182 - lr: 0.0010\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1847 - precision: 0.9470 - recall: 0.9286 - val_loss: 0.5946 - val_precision: 0.8524 - val_recall: 0.8155 - lr: 0.0010\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1844 - precision: 0.9462 - recall: 0.9255 - val_loss: 0.5918 - val_precision: 0.8537 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1806 - precision: 0.9473 - recall: 0.9311 - val_loss: 0.5902 - val_precision: 0.8554 - val_recall: 0.8189 - lr: 0.0010\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1792 - precision: 0.9489 - recall: 0.9315 - val_loss: 0.5915 - val_precision: 0.8519 - val_recall: 0.8166 - lr: 0.0010\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1839 - precision: 0.9466 - recall: 0.9280 - val_loss: 0.5985 - val_precision: 0.8483 - val_recall: 0.8151 - lr: 0.0010\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1825 - precision: 0.9458 - recall: 0.9281 - val_loss: 0.5990 - val_precision: 0.8490 - val_recall: 0.8109 - lr: 0.0010\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1794 - precision: 0.9500 - recall: 0.9301 - val_loss: 0.6003 - val_precision: 0.8473 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1822 - precision: 0.9466 - recall: 0.9287 - val_loss: 0.6014 - val_precision: 0.8481 - val_recall: 0.8136 - lr: 0.0010\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1787 - precision: 0.9459 - recall: 0.9286 - val_loss: 0.5991 - val_precision: 0.8475 - val_recall: 0.8124 - lr: 0.0010\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1798 - precision: 0.9488 - recall: 0.9303 - val_loss: 0.5962 - val_precision: 0.8492 - val_recall: 0.8166 - lr: 0.0010\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1803 - precision: 0.9484 - recall: 0.9293 - val_loss: 0.6028 - val_precision: 0.8485 - val_recall: 0.8140 - lr: 0.0010\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1818 - precision: 0.9442 - recall: 0.9256 - val_loss: 0.5984 - val_precision: 0.8486 - val_recall: 0.8147 - lr: 0.0010\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1777 - precision: 0.9470 - recall: 0.9288 - val_loss: 0.5904 - val_precision: 0.8545 - val_recall: 0.8201 - lr: 0.0010\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1796 - precision: 0.9456 - recall: 0.9292 - val_loss: 0.5921 - val_precision: 0.8558 - val_recall: 0.8197 - lr: 0.0010\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1808 - precision: 0.9455 - recall: 0.9256 - val_loss: 0.5997 - val_precision: 0.8510 - val_recall: 0.8151 - lr: 0.0010\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1811 - precision: 0.9451 - recall: 0.9290 - val_loss: 0.6051 - val_precision: 0.8470 - val_recall: 0.8136 - lr: 0.0010\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1787 - precision: 0.9464 - recall: 0.9278 - val_loss: 0.6001 - val_precision: 0.8472 - val_recall: 0.8166 - lr: 0.0010\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1756 - precision: 0.9492 - recall: 0.9331 - val_loss: 0.6056 - val_precision: 0.8470 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1794 - precision: 0.9481 - recall: 0.9291 - val_loss: 0.5993 - val_precision: 0.8487 - val_recall: 0.8132 - lr: 0.0010\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1748 - precision: 0.9472 - recall: 0.9282 - val_loss: 0.5953 - val_precision: 0.8499 - val_recall: 0.8186 - lr: 0.0010\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1771 - precision: 0.9467 - recall: 0.9283 - val_loss: 0.5960 - val_precision: 0.8502 - val_recall: 0.8163 - lr: 0.0010\n",
      "Unweighted f1: 0.8517637397586804, Weighted f1: 0.8374816449844547\n"
     ]
    }
   ],
   "source": [
    "# tc.fit_ensemble(5e-3,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kamin/Thai_NLP'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading deeplearning model\n",
      "loading logistic regression model\n",
      "loading the embedder and tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "TC = Text_classification_for_prediction( path_to_tfxidf= 'models_for_real_deployment/tf-idf_encoder.joblib',\n",
    "                                        model_path = 'models_for_real_deployment/text_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': {'billing and payment': 0.04239599199883396,\n",
       "  'international dialing': 0.002549459155609322,\n",
       "  'internet': 0.9208810924214039,\n",
       "  'lost and stolen': 0.0012800403966359952,\n",
       "  'other queries': 0.023315610086824624,\n",
       "  'promotions': 0.007684539984556279,\n",
       "  'true money': 0.0018932659561359188},\n",
       " 'deeplearning': {'billing and payment': 0.028904313,\n",
       "  'promotions': 0.0071565504,\n",
       "  'other queries': 0.007842738,\n",
       "  'internet': 0.9531318,\n",
       "  'international dialing': 0.0022579879,\n",
       "  'true money': 0.0004241576,\n",
       "  'lost and stolen': 0.0002824572}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TC.predict('ทำไมอินเตอร์เนตผมช้ามากๆเลยครับ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': {'billing and payment': 0.04957993119467105,\n",
       "  'international dialing': 0.01410676326467718,\n",
       "  'internet': 0.06836631971022208,\n",
       "  'lost and stolen': 0.8019789371395918,\n",
       "  'other queries': 0.03284068079988682,\n",
       "  'promotions': 0.03211143365895513,\n",
       "  'true money': 0.0010159342319958995},\n",
       " 'deeplearning': {'billing and payment': 0.0014396305,\n",
       "  'promotions': 4.500933e-05,\n",
       "  'other queries': 0.0007126399,\n",
       "  'internet': 0.00016222849,\n",
       "  'international dialing': 5.7639336e-05,\n",
       "  'true money': 1.607708e-05,\n",
       "  'lost and stolen': 0.9975668}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TC.predict('โทรศัพท์ผมหาย ผมต้องทำยังไงบ้างครับ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': {'billing and payment': 0.009000535616081102,\n",
       "  'international dialing': 0.9136489626289862,\n",
       "  'internet': 0.004919699100065405,\n",
       "  'lost and stolen': 0.0023058219177843234,\n",
       "  'other queries': 0.053685728274877664,\n",
       "  'promotions': 0.014218651980250626,\n",
       "  'true money': 0.0022206004819546364},\n",
       " 'deeplearning': {'billing and payment': 0.003268424,\n",
       "  'promotions': 0.0007003219,\n",
       "  'other queries': 0.0016304805,\n",
       "  'internet': 0.0005526525,\n",
       "  'international dialing': 0.99374676,\n",
       "  'true money': 3.111233e-05,\n",
       "  'lost and stolen': 7.024724e-05}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TC.predict('สอบถามบริการโทรต่างประเทศน่ะครับ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
