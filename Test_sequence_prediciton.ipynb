{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import pythainlp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Word_Embedder\n",
    "from preprocessing import Text_processing\n",
    "from text_classification import Text_classification, Text_classification_for_prediction, count_based_model\n",
    "from text_classification import prepare_data_for_text_classification, prepare_data_for_sequence_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:\\\\Coding_projects\\\\data\\\\NER\\\\BEST10\\\\Current\\\\all_without_sw_clean2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = []\n",
    "with open('BEST10_no_sw_tr.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            tr.append(line)\n",
    "te = []\n",
    "with open('BEST10_no_sw_te.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            te.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17392\n",
      "4020\n"
     ]
    }
   ],
   "source": [
    "print(len(tr))\n",
    "print(len(te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:\\\\Coding_projects\\\\Thai_NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = Text_processing(max_len=64,min_len=5,min_len_character=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tp.preprocessing2(tr,do_padding=True)\n",
    "test = tp.preprocessing2(te, do_padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NR': 0,\n",
       " 'VV': 1,\n",
       " 'NN': 2,\n",
       " 'DDEM': 3,\n",
       " 'JJV': 4,\n",
       " 'P': 5,\n",
       " 'JJA': 6,\n",
       " 'PINT': 7,\n",
       " 'NEG': 8,\n",
       " 'AUX': 9,\n",
       " 'CNJ': 10,\n",
       " 'ADV': 11,\n",
       " 'FXN': 12,\n",
       " 'PDT': 13,\n",
       " 'CL': 14,\n",
       " 'OD': 15,\n",
       " 'COMP': 16,\n",
       " 'REFX': 17,\n",
       " 'VA': 18,\n",
       " 'FXG': 19,\n",
       " 'DINT': 20,\n",
       " 'PPER': 21,\n",
       " 'PDEM': 22,\n",
       " 'CD': 23,\n",
       " 'PAR': 24,\n",
       " 'DPER': 25,\n",
       " 'FXAV': 26,\n",
       " 'FXAJ': 27,\n",
       " 'FWV': 28,\n",
       " 'FWA': 29,\n",
       " 'FWN': 30,\n",
       " 'PU': 31,\n",
       " 'IJ': 32,\n",
       " 'blank': 33,\n",
       " 'FWX': 34,\n",
       " '': 35}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "train[1]['-PAD-'] = len(train[1])\n",
    "tmp = prepare_data_for_sequence_prediction(train,\n",
    "                                           test,\n",
    "                                           max_len=64,\n",
    "                                           min_len=5,\n",
    "                                           unique_labels = train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the path: trained_models\\sequence_prediction\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_vectors (InputLayer)       [(None, 64, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masks (InputLayer)              [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 64, 256)      330240      word_vectors[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 64, 256)      296448      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 256)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 64, 64)       16448       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64)       256         time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 64, 64)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64)       0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 64, 32)       2080        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 32)       128         time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 64, 32)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 32)       0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 64, 21)       693         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 21)       84          time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 64, 21)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 21)       0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "seq_out (TimeDistributed)       (None, 64, 37)       814         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 647,191\n",
      "Trainable params: 646,957\n",
      "Non-trainable params: 234\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tc = Text_classification(prepared_data_dict=tmp,\n",
    "                         do_deep_learning=True,\n",
    "                         do_linear_classifier=False,\n",
    "                         is_sequence_prediciton=True,\n",
    "                         model_path='sequence_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "    237/Unknown - 37s 155ms/step - loss: 3.6339"
     ]
    }
   ],
   "source": [
    "tc.fit_deep_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_bay",
   "language": "python",
   "name": "text_bay"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
